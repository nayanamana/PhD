#!/usr/local/bin/python3.8

import os, re, sys

sys.path.append(os.path.dirname(os.path.realpath(__file__)) + '/lib')

import hashlib
import json
import os
import re
import requests
import logging
import sys
import time
import urllib

import traceback

from selenium import webdriver
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

from selenium.webdriver.firefox.options import Options

logger = logging.getLogger('phishing')

#############################
# Parameters. Modify these! #
#############################

# path to a Firefox log file
#FFLOG = "/Users/marchas1/Desktop/firefox_log.txt"
#FFLOG = os.path.abspath("./firefox_log.txt")

# Default root for storing sitedata
#DLROOT = "/Users/marchas1/Desktop/"
DLROOT = os.path.abspath(".")

def _kill_firefox():
     """
     Kill  **all** Firefox instances
     """
     os.system("""kill -9 `ps -ef | awk '/firefox/{print $2}'`""")

def save_screenshot(domain, url, out_dir):
 d = None
 vp_width = 1200
 vp_height = 900

 #url = url.replace('https','http') #REMOVE
 #print(url)

 try:
   chrome_options = Options()
   chrome_options.add_argument('--headless')
   chrome_options.add_argument('--no-sandbox')
   chrome_options.add_argument('--disable-dev-shm-usage')
   chrome_options.add_argument('--user-agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36"')
   d = webdriver.Chrome('/mnt/extra1/projects/phishing/drivers/chromedriver',chrome_options=chrome_options)
   d.set_window_size(vp_width, vp_height)
   d.set_page_load_timeout(30)
   #d.set_page_load_timeout(15)
   d.get(url)
   #final_url = d.current_url
   #ext_final_url = tldextract.extract(final_url)
   #CHECK LATER
   #if ext_final_url and ext_final_url.domain in feature_extract.get_alexa_doms_sld():
   #    write_to_skipped_log("redirected to popular domain  -- " + domain)
   #    raise Exception("redirected to popular domain  -- " + domain)

   #page_source = d.page_source
   #with open(out_dir + '/' + domain + '.html', 'w+') as f:
   #   f.write(d.page_source)
   d.save_screenshot(out_dir + '/' + domain + '.png')
   d.quit()
 except Exception as e:
   print(str(e))
   traceback.print_exc(file=sys.stdout)
 finally:
   try:
     d.close()
   except Exception as e:
      pass


def fetch_sitedata_and_screenshot(url, is_phish, dirname):
        """
        Fetch and sitedata and screenshot.

        Parameters
        ----------
        url: string
            URL of the website

        Returns
        -------
        sitedata: dict
            contains textual data extracted from a site
        screenshot: bytes or None
            binary for the screenshot
        """
        sitedata = {}

        parsed = urllib.parse.urlparse(url)
        if not parsed.scheme:
            starturl = 'http://' + url
        else:
            starturl = url

        #print("SITEURL: " + starturl)

        sitedata['starturl'] = starturl

        headers = {'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.9; rv:32.0) Gecko/20100101 Firefox/32.0',}
        try:
            r = requests.get(starturl, headers=headers, timeout=5)
            landurl = r.url
        except (KeyboardInterrupt, SystemExit):
            raise
        except:
            logger.info("error in requesting url with requests: {}".format(sys.exc_info()[0]))
            sitedata['redirections'] = []
        else:
            redirections = [link.url for link in r.history]
            sitedata['redirections'] = redirections
            for rdir in redirections:
                logger.info(rdir, nots=True)

        # clean Firefox log file
        #with open(FFLOG, 'w') as f:
        #    f.write('')

        options = Options()
        #options.set_headless(headless=True)
        options.headless = True
        driver = webdriver.Firefox(options=options)
        #driver = webdriver.Firefox()
        #driver.set_page_load_timeout(20)
        driver.set_page_load_timeout(20)

        try:
            driver.maximize_window()
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            driver.quit()
            _kill_firefox()
            logger.info("error in maximizing  window:", sys.exc_info()[0])

        try:
            driver.get(starturl)
            time.sleep(5)
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            driver.quit()
            _kill_firefox()
            logger.info("FATAL error in fetching landing url with webdriver:", sys.exc_info()[0])
            return {}, None

        '''
        try:
            WebDriverWait(driver, 5).until(EC.alert_is_present(),
                                   'Timed out waiting for PA creation ' +
                                   'confirmation popup to appear.')

            alert = driver.switch_to_alert()
            alert.accept()
            print("alert accepted")
        #except TimeoutException:
        except Exception as e:
            #print("no alert")
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
        '''

        try:
            landurl = driver.current_url
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            driver.quit()
            _kill_firefox()
            logger.info("FATAL error in fetching landing url with webdriver:", sys.exc_info()[0])
            return {}, None

        sitedata['landurl'] = landurl

        try:
            screenshot = driver.get_screenshot_as_png()
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            driver.quit()
            _kill_firefox()
            logger.info("FATAL Error in saving a screenshot: {}".format(sys.exc_info()[0]))
            return {}, None

        try:
            title = driver.title
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            logger.info("error in saving title: {}".format(sys.exc_info()[0]))
        sitedata['title'] = title

        try:
            source = driver.page_source
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            driver.quit()
            _kill_firefox()
            logger.info("FATAL Error in saving html source: {}".format(sys.exc_info()[0]))
            return {}, None
        sitedata['source'] = source

        try:
            elem = driver.find_element_by_tag_name('body')
            text = elem.text
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            logger.info("error in extracting content text: {}".format(sys.exc_info()[0]))
            text = ''
        sitedata['text'] = text

        try:
            driver.quit()
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            # self.logger.info("problem while trying to quit the driver: {}".format(sys.exc_info()[0]))
            _kill_firefox()

        '''
        # extract links from firefox log
        loglinks = set()
        try:    # UnicodeDecodeError
            with open(FFLOG, 'r') as f:
                logtext = f.read()
                for match in re.finditer(r"uri=(http.+)\]", logtext):
                    uri = match.group(1)
                    loglinks.add(uri)
            sitedata['loglinks'] = sorted(loglinks)
        except Exception as e:
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            print("error")
            sitedata['loglinks'] = []

        # fetching source from external html and php pages
        found = False
        sitedata['external_source'] = {}
        for ext_url in loglinks:
            if ext_url.endswith('.php') or ext_url.endswith('.html'):
                # this ugly arrangement ensures that Firefox is launched only if needed
                if not found:
                    driver = webdriver.Firefox()
                    driver.set_page_load_timeout(5)
                    found = True
                try:
                    driver.get(ext_url)
                    # time.sleep(2)
                    source = driver.page_source
                    sitedata['external_source'][ext_url] = source
                #except (KeyboardInterrupt, SystemExit):
                #    raise
                except Exception as e:
                    traceback.print_exc(limit=2, file=sys.stdout)
                    print(str(e))
                    self.logger.info("failed")
        '''

        sitedata['access_time'] = time.ctime()
        sitedata['is_phish'] = is_phish
        try:
            driver.quit()
        #except (KeyboardInterrupt, SystemExit):
        #    raise
        except Exception as e:
            # self.logger.info("problem while trying to quit the driver: {}".format(sys.exc_info()[0]))
            traceback.print_exc(limit=2, file=sys.stdout)
            print(str(e))
            _kill_firefox()
        #print(sitedata.keys())
        siteid = hashlib.sha1((sitedata['starturl'] + sitedata['landurl'] + sitedata['source']).encode()).hexdigest()
        sitedata['siteid'] = siteid

        #Take screenshot
        #save_screenshot(url, start_url, dirname)

        return sitedata, screenshot

def get_web_domain(url):
       re_dom = re.search('://(.+?)/', url)
       dom = ""
       if re_dom:
          dom = re_dom.group(1)
       else:
          re_dom = re.search('://(.+)', url)
          if re_dom:
             dom = re_dom.group(1)
       return dom

#def save_data(self, sitedata, screenshot, dlroot=None):
def save_data(url, sitedata, screenshot, dirname):
        """
        Save the data obtained from the output of the function
        fetch_sitedata_and_screenshot().

        Parameters
        ----------
        sitedata: json object
        screenshot: binary png
        dlroot: string or None
            Path to the root in which the data is to be stored. The files are
            saved in the following paths: jspath: dlroot/sitedata/<siteid>.json
            sspath: dlroot/screenshots/<siteid>.png If not given, dlroot is set
            to DLROOT

        Returns
        -------
        jspath: str
            path to the json file
        sspath: str
            path to the screenshot file
        """
        # OLD DOWNLOAD SCHEME. OK TO DELETE
        # # ensure that sitedata and screenshots directories exist
        # dirname = os.path.join(dlroot, 'sitedata')
        # if not os.path.exists(dirname):
        #     os.mkdir(dirname)
        # dirname = os.path.join(dlroot, 'screenshots')
        # if not os.path.exists(dirname):
        #     os.mkdir(dirname)
        # jspath = os.path.join(dlroot, 'sitedata', sitedata['siteid'] + '.json')
        # sspath = os.path.join(dlroot, 'screenshots', sitedata['siteid'] + '.png')

        #if dlroot is None:
        #    dlroot = DLROOT
        # ensure that websites directory exist
        #dirname = os.path.join(dlroot, 'websites')
        if not os.path.exists(dirname):
            os.mkdir(dirname)
        #print("DIR: " + dirname)
        dom = get_web_domain(url)
        #jspath = os.path.join(dirname, sitedata['siteid'] + '.json')
        #sspath = os.path.join(dirname, sitedata['siteid'] + '.png')
        jspath = os.path.join(dirname, dom + '.json')
        sspath = os.path.join(dirname, dom + '.png')

        #print(jspath)

        with open(jspath, 'w') as f:
            json.dump(sitedata, f, indent=0, sort_keys=True)
        with open(sspath, 'wb') as f:
            f.write(screenshot)
        return jspath, sspath

#def fetch_and_save_data(self, url, dlroot=None):
def fetch_and_save_data(url, dirname, is_phish):
        """
        Fetch and save data from a give url.

        This function simply combines `etch_sitedata_and_screenshots() and
        save_data(). Look at theis doc strings for further info.
        """
        sitedata, screenshot = fetch_sitedata_and_screenshot(url, is_phish, dir_name)
        #print(sitedata)
        if not sitedata:
            logger.info("failed to fetch url")
            return '', ''
        #jspath, sspath = save_data(sitedata, screenshot, dlroot=dlroot)
        jspath, sspath = save_data(url, sitedata, screenshot, dirname)
        return jspath, sspath



